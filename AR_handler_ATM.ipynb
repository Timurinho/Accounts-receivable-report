{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf75e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime, os, io\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Users/atm/Desktop/data/from VJI/\"\n",
    "# ------------\n",
    "FILE_N_dict = {'big': 'big_upload', 'raw': \"raw_upload\", 'date': \"date_upload\"}\n",
    "# ------------\n",
    "FILE_codes = \"База данных для кодов клиента\"\n",
    "FILE_codes_upd = 'База данных для кодов клиента_обновление'\n",
    "FILE_ZPART = \"ZPART_BI_REP\"\n",
    "\n",
    "FMT = \".xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переменные для основного DataFrame\n",
    "SH_NAME = \"Основной\"\n",
    "# ---------\n",
    "AR_columns_date = [\"Контрагент\", \"Документ\", \"Дата\", \"Сумма\", \"Валюта\", \"Дата погашения\", \n",
    "                   \"Дни просрочки САП\", \"Итого дебиторская задолженность\", \n",
    "                   \"Просроченная дебиторская задолженность САП\", \"Плановая дебиторская задолженность\", \n",
    "                   \"Дата формирования отчета\"]\n",
    "AR_columns_raw = AR_columns_date[:-1] + [\"Сектор\"] + [\"Дата формирования отчета\"]\n",
    "AR_columns_dict = {'date': AR_columns_date, 'raw': AR_columns_raw}\n",
    "# ----------\n",
    "\n",
    "COLUMNS_XLS_dict = {'date': \"C:M\", 'raw': \"C:N\"}\n",
    "\n",
    "SKIP_ROWS = 8\n",
    "\n",
    "nrows = None\n",
    "clients_to_skip = ['АО \"НМЖК\"', 'АО ТД \"НМЖК\"', 'ИП Варламова Е.Л.', 'ИП Варламова Елена Леонидовна',\n",
    "                  'ООО \"Свит Лайф Фудсервис\"', 'OBA MARKET OOO', 'ООО \"Главмолснаб\"', 'ТОО \"Сауда-Интер\"',\n",
    "                  'ООО \"Восток-Запад\"', 'ООО \"Три-С Фуд Ритейл\"']\n",
    "\n",
    "commersants = ['Букаев Алексей Евгеньевич', 'Вылегженин Илья Леонидович', 'Гурова Елена Владимировна', \n",
    "               'Зайцев Александр Николаевич', 'Кабанов Вячеслав Юрьевич', 'Клячин Евгений Александрович', \n",
    "               'Кожемякин Иван Анатольевич', 'Кондратьев Максим Владимирович', 'Корнев Роман Александрович', \n",
    "               'Кутузова Ирина Геннадьевна', 'Ливенцев Сергей Владимирович', 'Митрофанов Григорий Николаевич', \n",
    "               'Мосюров Сергей Николаевич', 'Новиков Юрий Валерьевич', 'Чурилов Михаил Юрьевич', \n",
    "               'Кутлуев Эдуард Фанилевич']\n",
    "\n",
    "\n",
    "# переменные для DataFrame с кодами ГП\n",
    "CODES_columns = [\"Наименование контрагента\", \"№ счета-фактуры\", \"Грузополучатель\"]\n",
    "codes_sheet = 'Sheet1'\n",
    "\n",
    "# переменные для ZPART_BI_REP DataFrame\n",
    "ZPART_sheet = 'Sheet1'\n",
    "ZPART_columns = [\"ID_GRUZOPOL\", \"HOLDING\", \"REGION_B2C\", \"COMMERSANT_B2C\", \"CHANNEL\"]\n",
    "\n",
    "# регионы и директора\n",
    "\n",
    "directors = {'ВОЛГА ВЕРХНЯЯ': 'DISTR /Вылегженин', 'ВОЛГА НИЖНЯЯ': 'DISTR /Вылегженин', \n",
    "             'ВОСТОК': 'DISTR /Вылегженин', 'МОСКВА': 'DISTR /Кротова', 'СЕВЕРО-ЗАПАД': 'DISTR /Кротова', \n",
    "             'УРАЛ': 'DISTR /Вылегженин', 'ЦЕНТР': 'DISTR /Кротова','ЮГ': 'DISTR /Кротова'}\n",
    "\n",
    "\n",
    "final_columns = [\"Контрагент\", \"Документ\", \"Дата\", \"Сумма\", \"Валюта\", \"Дата погашения\", \n",
    "                   \"Дни просрочки САП\", \"Итого дебиторская задолженность\", \n",
    "                   \"Просроченная дебиторская задолженность САП\", \"Плановая дебиторская задолженность\", \n",
    "                   \"Дата формирования отчета\", \"Код грузополучателя\", \"Холдинг\", \"Бизнес регион\", \n",
    "                   \"Коммерсант\", \"Канал\", \"Директор\", \"Дни просрочки\", \"Итого просроченная задолженность\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обновляем таблицу \"база данных клиентов\" данными за последние два месяца. старые удаляем, новые добавляем;\n",
    "\n",
    "def months_since_epoch(date):\n",
    "    return 12*(date.year - 1970) + (date.month - 1)\n",
    "\n",
    "def client_code_updater(nrows=None):\n",
    "    t0 = time.time()\n",
    "    # импорты файлов\n",
    "    client_code = pd.read_excel(PATH + FILE_codes + FMT, sheet_name=codes_sheet,\n",
    "                                header=0, usecols=\"A:K\", nrows=None)\n",
    "    client_code_columns = client_code.columns.to_list()\n",
    "    client_code_upd = pd.read_excel(PATH + FILE_codes_upd + FMT, sheet_name=codes_sheet, \n",
    "                                    header=0, usecols=\"A:K\", nrows=None)\n",
    "\n",
    "    \n",
    "    month_upd_lower = months_since_epoch(min(client_code_upd['Дата фактуры'])) # ищем \"меньшую\" дату в файле \"свеж.\" фактур\n",
    "    \n",
    "    # новый столбец в файле-обнов. с числом месяцев с \"эпохальной даты\"\n",
    "    client_code_upd['месяцев_от_1970'] = client_code_upd['Дата фактуры'].map(months_since_epoch)\n",
    "    # удалить те фактуры, которые в основном файле датированы  теми же месяцами, что и фактуры в \"обнове\"\n",
    "    client_code['месяцев_от_1970'] = client_code['Дата фактуры'].map(months_since_epoch) >= month_upd_lower\n",
    "    client_code = client_code.drop(client_code[client_code[\"месяцев_от_1970\"]].index)\n",
    "    \n",
    "    # объединить остаток из основного файла с данными из файл со свежими фактурами\n",
    "    client_code = pd.concat([client_code, client_code_upd]).iloc[:, :-1]\n",
    "    client_code.to_excel(PATH + FILE_codes + FMT, sheet_name=codes_sheet, index=False)\n",
    "    t1 = time.time()\n",
    "    print(\"файл с кодами клиентов обновлён за:\", round(t1-t0), \"секунд\")\n",
    "\n",
    "    \n",
    "    \n",
    "def client_code_updater_v2(nrows=None):\n",
    "    t0 = time.time()\n",
    "    # импорты файлов\n",
    "    client_code = pd.read_excel(PATH + FILE_codes + FMT, sheet_name=codes_sheet,\n",
    "                                header=0, usecols=\"A:K\", nrows=None)\n",
    "    client_code_upd = pd.read_excel(PATH + FILE_codes_upd + FMT, sheet_name=codes_sheet, \n",
    "                                    header=0, usecols=\"A:K\", nrows=None)\n",
    "\n",
    "    client_code = (pd.concat([client_code, client_code_upd])).drop_duplicates()\n",
    "    client_code.to_excel(PATH + FILE_codes + FMT, sheet_name=codes_sheet, index=False)\n",
    "    t1 = time.time()\n",
    "    print(\"файл с кодами клиентов обновлён за:\", round(t1-t0), \"секунд\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b225375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_table_create():\n",
    "    \"\"\" просто создаёт таблицу с инфо по задолженностям в БД \"\"\"\n",
    "    try:\n",
    "        # connect to db\n",
    "        connection = psycopg2.connect(\n",
    "            host=\"localhost\", \n",
    "            user=\"postgres\", \n",
    "            password=\"zXbkfdtr10-nmgk\", \n",
    "            database='AR'\n",
    "        )\n",
    "        connection.autocommit = True\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\n",
    "                \"SELECT version()\"\n",
    "            )\n",
    "            print(f\"Server version: {cursor.fetchone()}\")\n",
    "\n",
    "        with connection.cursor() as cursor:\n",
    "    #         cursor.execute(\n",
    "    #             \"\"\"DROP TABLE IF EXISTS sap_report_ar\"\"\"\n",
    "    #         )\n",
    "    #         print(\"[INFO] Table deleted\")\n",
    "\n",
    "            cursor.execute(\n",
    "                \"\"\"CREATE TABLE IF NOT EXISTS sap_report_ar(\n",
    "                id serial PRIMARY KEY,\n",
    "                \"Контрагент\" VARCHAR(100),\n",
    "                \"Документ\" VARCHAR(100),\n",
    "                \"Дата\" DATE,\n",
    "                \"Сумма\" NUMERIC,\n",
    "                \"Валюта\" VARCHAR(100),\n",
    "                \"Дата погашения\" DATE,\n",
    "                \"Дни просрочки САП\" SMALLINT,\n",
    "                \"Итого дебиторская задолженность\" NUMERIC,\n",
    "                \"Просроченная дебиторская задолженность САП\" NUMERIC,\n",
    "                \"Плановая дебиторская задолженность\" NUMERIC,\n",
    "                \"Дата формирования отчета\" DATE,\n",
    "                \"Код грузополучателя\" BIGINT,\n",
    "                \"Холдинг\" VARCHAR(100),\n",
    "                \"Бизнес регион\" VARCHAR(100),\n",
    "                \"Коммерсант\" VARCHAR(100),\n",
    "                \"Канал\" VARCHAR(100),\n",
    "                \"Директор\" VARCHAR(100),\n",
    "                \"Дни просрочки\" SMALLINT,\n",
    "                \"Итого просроченная задолженность\" NUMERIC);\n",
    "                \"\"\"\n",
    "            )\n",
    "            print(\"[INFO] Table successfully created\")\n",
    "    except Exception as ex:\n",
    "        print(\" [INFO] Error while working with PostgreSQL\", ex)\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n",
    "            print(\"[INFO] PostgreSQL connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_table_drop():\n",
    "    \"\"\" удаляет таблицу по задолженностям из БД, если она существует \"\"\"\n",
    "    try:\n",
    "        # connect to db\n",
    "        connection = psycopg2.connect(\n",
    "            host=\"localhost\", \n",
    "            user=\"postgres\", \n",
    "            password=\"zXbkfdtr10-nmgk\", \n",
    "            database='AR'\n",
    "        )\n",
    "        connection.autocommit = True\n",
    "\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\n",
    "                \"\"\"DROP TABLE IF EXISTS sap_report_ar\"\"\"\n",
    "            )\n",
    "            print(\"[INFO] Table deleted\")\n",
    "    except Exception as ex:\n",
    "        print(\" [INFO] Error while working with PostgreSQL\", ex)\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n",
    "            print(\"[INFO] PostgreSQL connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40423f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_by_date(date):\n",
    "    \"\"\" Удаляет из БД данные за выбранную дату \"\"\"\n",
    "    date_to_delete = date\n",
    "    try:\n",
    "        connection = psycopg2.connect(dbname='AR', user='postgres', password='zXbkfdtr10-nmgk', host='localhost')\n",
    "        connection.autocommit =  True\n",
    "\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\n",
    "            \"\"\"\n",
    "            SELECT DISTINCT \"Дата формирования отчета\" FROM sap_report_ar\n",
    "            \"\"\"\n",
    "            )\n",
    "            result = [el[0].strftime(\"%Y-%m-%d\") for el in cursor.fetchall()]\n",
    "            if date_to_delete in result:\n",
    "                date_to_delete = str(\"'\") + date_to_delete + str(\"'\")\n",
    "                cursor.execute(\n",
    "                \"\"\"\n",
    "                DELETE FROM sap_report_ar WHERE \"Дата формирования отчета\" = {}\n",
    "                \"\"\".format(date_to_delete)\n",
    "                )\n",
    "                print(\"[INFO] Data by period successfully deleted\")\n",
    "            else:\n",
    "                print(\"[INFO] Date not found\")\n",
    "    except Exception as ex:\n",
    "        print(\" [INFO] Error while working with PostgreSQL\", ex)\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n",
    "            print(\"[INFO] PostgreSQL connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_base_to_csv():\n",
    "    \"\"\"скопировать основную таблицу из БД в .csv файл\"\"\"\n",
    "    \n",
    "    # create a query to specify which values we want from the database.\n",
    "    query = \"SELECT * FROM sap_report_ar\"\n",
    "\n",
    "    # set up our database connection.\n",
    "    conn = psycopg2.connect(dbname='AR', user='postgres', password='zXbkfdtr10-nmgk', host='localhost')\n",
    "    db_cursor = conn.cursor()\n",
    "\n",
    "    # Use the COPY function on the SQL we created above.\n",
    "    SQL_for_file_output = \"COPY ({0}) TO STDOUT WITH CSV HEADER ENCODING 'UTF-8'\".format(query)\n",
    "\n",
    "    # Set up a variable to store our file path and name.\n",
    "    t_path_n_file = PATH + 'download.csv'\n",
    "    with open(t_path_n_file, 'w') as f_output:\n",
    "        db_cursor.copy_expert(SQL_for_file_output, f_output)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58322ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def previously_stored_csv_to_sql():\n",
    "    dataframe = pd.read_csv(PATH+'download.csv', encoding='cp1251')\n",
    "    engine = create_engine('postgresql+psycopg2://postgres:zXbkfdtr10-nmgk@localhost:5432/AR')\n",
    "    dataframe.to_sql('sap_report_ar', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b049ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AR_Handler:\n",
    "    def __init__(self, method):\n",
    "        '''\n",
    "        выбрать один из методов обработки файла: \"raw\", \"big\" or \"date\"\n",
    "        '''\n",
    "        t_begin = time.time()\n",
    "        if method not in {'raw', 'date', 'big'}:\n",
    "            raise BaseException(\"<< {} >> is incorrect. Choose one of these: 'big', 'raw' or 'date'\" \\\n",
    "                                .format(method)) # ошибка, если юзер запустит код с неправ-м методом\n",
    "        \n",
    "#         ---------------------------------------------------------------------------------\n",
    "        self.engine = create_engine('postgresql+psycopg2://postgres:zXbkfdtr10-nmgk@localhost:5432/AR')\n",
    "        self.conn = self.engine.raw_connection()\n",
    "#         self.cur = self.conn.cursor()\n",
    "#         self.output = io.StringIO()\n",
    "        \n",
    "#         -----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # РАБОТА С ГЛАВНЫМ ФАЙЛОМ\n",
    "        # определяем требуемые имена и списки\n",
    "        if method == 'big':\n",
    "            FILE_N = FILE_N_dict['big']\n",
    "            method = 'date'\n",
    "            sql_table_drop()\n",
    "            sql_table_create()\n",
    "        else:\n",
    "            FILE_N = FILE_N_dict[method]\n",
    "        COLUMNS_NAMES, COLUMNS_XLS = AR_columns_dict[method], COLUMNS_XLS_dict[method]\n",
    "        \n",
    "        \n",
    "\n",
    "        self.df = pd.read_excel(PATH + FILE_N + FMT, sheet_name=SH_NAME, header=None, names=COLUMNS_NAMES,\n",
    "                                usecols=COLUMNS_XLS, skiprows=SKIP_ROWS, nrows=nrows) # импорт файла\n",
    "\n",
    "        #\n",
    "        if method == 'raw':\n",
    "            self.date_var = self.df.iloc[0,-1]\n",
    "            self.df['Чья задолженность'], self.df['Коммерсант'] = np.nan, np.nan\n",
    "            self.tech_var = np.nan\n",
    "            self.df = self.df.apply(self.__fill_commers, axis=1) # определяем ответственных коммерсантов\n",
    "            self.df = self.df.apply(self.__b2c_accounts, axis=1) # определим строки, относящиеся к B2C\n",
    "            self.df = self.df[self.df['Чья задолженность']=='B2C'].iloc[:,:-4]\n",
    "            # добавляет в файл дату выгрузки отчета\n",
    "            if method == 'raw':\n",
    "                self.df[\"Дата формирования отчета\"] = self.date_var\n",
    "            \n",
    "        # отбрасывает ненужных контрагентов и строки без даты документа\n",
    "        self.df = self.df[(~self.df['Контрагент'].isin(clients_to_skip)) & (~self.df[\"Дата\"].isna())]\n",
    "        \n",
    "\n",
    "#         self.df[\"Дата\"] = self.df['Дата'].map(self.date_convert) # в поле \"дата\" могут быть числ. xls форматы, исправляет\n",
    "        self.df[\"Дата\"] = self.df['Дата'].map(lambda date: self.convert_excel_time(date) if type(date)==int \\\n",
    "                                              else date) # в поле \"дата\" могут быть числ. xls форматы, исправляет\n",
    "    \n",
    "\n",
    "        self.df[\"Док_клиент\"] = self.df[\"Контрагент\"].map(str) + self.df[\"Документ\"].map(str) # сцепка КА и кода документа\n",
    "\n",
    "        \n",
    "#         -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # вспомог-й DF с кодами клиентов, будем его далее присоединять\n",
    "\n",
    "        self.client_code = pd.read_excel(PATH + FILE_codes + FMT, sheet_name=codes_sheet, header=0, \n",
    "                                      usecols=CODES_columns, nrows=None) # import\n",
    "\n",
    "\n",
    "        \n",
    "        # сцепка КА и кода док-та, убираются дубликаты, чтобы одной связке соответствовал лишь один код ГП\n",
    "\n",
    "        self.client_code[\"Док_клиент\"] = self.client_code[\"Наименование контрагента\"].map(str) \\\n",
    "                                        + self.client_code[\"№ счета-фактуры\"].map(str)\n",
    "        self.client_code = self.client_code.loc[:, [\"Док_клиент\", \"Грузополучатель\"]] \\\n",
    "                            .drop_duplicates(\"Док_клиент\").set_index('Док_клиент')[\"Грузополучатель\"]\n",
    "\n",
    "        self.df[\"Грузополучатель\"] = self.df[\"Док_клиент\"].map(self.client_code) # подтягивается ГП сцепкой из ориг. DF\n",
    "        self.df.drop(columns=[\"Док_клиент\"], inplace=True)\n",
    "#         -----------------------------------------------------------------------------------------------------    \n",
    "#         # выгружаем имеющиеся данные из БД, добавляем к ней наши новые данные, сохраняем\n",
    "        self.sql_query = \"SELECT * FROM sap_report_ar\"\n",
    "        self.date_cols = [\"Дата\", \"Дата погашения\", \"Дата формирования отчета\"] # столбцы с датами для корр-й работы ф-и\n",
    "        self.db_df = pd.read_sql(self.sql_query, self.conn, parse_dates=self.date_cols).iloc[:, 1:-7] # выгрузка из БД\n",
    "        self.conn.close()\n",
    "        self.db_df.columns = self.df.columns\n",
    "        self.df_new = pd.concat([self.df, self.db_df]) # объединить данные из БД и новые\n",
    "#         -----------------------------------------------------------------------------------------------------        \n",
    "#         # другой вспомог-й DF\n",
    "\n",
    "        # import ZPART_BI_REP\n",
    "        \n",
    "        self.zpart_bi_rep = pd.read_excel(PATH + FILE_ZPART + FMT, sheet_name=ZPART_sheet, header=0, \n",
    "                                          usecols=ZPART_columns)\n",
    "        \n",
    "        \n",
    "#         # создаём финальный DF на основе предыдущих, отбрасываем ненужные столцбы\n",
    "\n",
    "        self.df_new = self.df_new.merge(self.zpart_bi_rep.drop_duplicates(), how='left', left_on=\"Грузополучатель\", \n",
    "                                    right_on=\"ID_GRUZOPOL\").drop(columns=[\"ID_GRUZOPOL\"])\n",
    "\n",
    "#         self.df_new[\"Грузополучатель\"] = self.df_new[\"Грузополучатель\"].astype('int64')\n",
    "#         -----------------------------------------------------------------------------------------------------        \n",
    "        # заполняет столбец \"директор\"\n",
    "        self.df_new['Директор'] = self.df_new.apply(lambda row: directors[row['REGION_B2C']] if row['CHANNEL'] == 'DISTR' \n",
    "                                                    else row['CHANNEL'], axis=1)\n",
    "\n",
    "        # высчитываем корректные дни просрочки и сумму просроченной задолженности, сначала сделаем копии ориг-х столбцов\n",
    "        self.df_new['Дни просрочки'] = self.df_new['Дни просрочки САП'].copy()\n",
    "        self.df_new['Просроченная дебиторская задолженность'] = self.df_new['Просроченная дебиторская задолженность САП'].copy()\n",
    "        self.df_new = self.df_new.apply(self.__overdue, axis=1) # конечное число дней и суммы (дебит-й) просрочки\n",
    "    \n",
    "        self.df_new.columns = final_columns # переименовали столбцы\n",
    "\n",
    "        t_end = time.time()\n",
    "        print(\"Конструктор класса отработал за:\", round(t_end - t_begin), \"секунд\")\n",
    "\n",
    "        \n",
    "#         ------------------------------------------------------------------------------------\n",
    "#         ------------------------------------------------------------------------------------\n",
    "#         ------------------------------------------------------------------------------------\n",
    "#         ------------------------------------------------------------------------------------\n",
    "#         ------------------------------------------------------------------------------------\n",
    "        \n",
    "    def __AR_base_date(self, path):\n",
    "        ''' возвращает дату создания файла отчёта по ДЗ в формате дд.мм.гггг'''\n",
    "        self.t = os.path.getctime(path) # дата и время создания файла\n",
    "        self.t_for_df = datetime.date.fromtimestamp(self.t) # дата и время в формате datetime\n",
    "        return self.t_for_df\n",
    "    \n",
    "    def __overdue(self, row):\n",
    "        \"\"\" отриц-е дни просрочки равняет 0; для НКА просрочка < 4 дней допустима (=0), для ост-о вернуть данные САП\"\"\"\n",
    "        if row['Дни просрочки САП'] < 1:\n",
    "            row[\"Дни просрочки\"] = np.nan\n",
    "        else:\n",
    "            if row['CHANNEL'] == \"NKA\" and row['Дни просрочки САП'] <= 4:\n",
    "                row[\"Дни просрочки\"] = np.nan\n",
    "                row[\"Просроченная дебиторская задолженность\"] = 0\n",
    "        return row\n",
    "\n",
    "    def __fill_commers(self, row):\n",
    "        ''' заполняет поле коммерсант '''\n",
    "        if pd.isnull(row[\"Валюта\"]):\n",
    "            row['Коммерсант'] = row['Контрагент']\n",
    "            self.tech_var = row['Контрагент']\n",
    "        else:\n",
    "            row['Коммерсант'] = self.tech_var\n",
    "        return row\n",
    "        \n",
    "    def __b2c_accounts(self, row):\n",
    "        \"\"\" определяет строки, относящиеся к B2C \"\"\"\n",
    "        if (np.isnan(row['Сектор']) and row['Контрагент'] == 'АО \"Торговый дом \"Перекресток\"') \\\n",
    "        or row['Коммерсант'] in commersants \\\n",
    "        or (row['Сектор'] == 2 and any(x in str(row['Коммерсант']) for x in ['ДИКСИ', 'МЕТРО', 'Перекресток'])):\n",
    "            row['Чья задолженность'] = 'B2C'\n",
    "        return row\n",
    "\n",
    "    def convert_excel_time(self, excel_time):\n",
    "        ''' converts number of days since 1970.01.01 into date as it is in MS Excel  '''\n",
    "        adj = 1 if excel_time < 60 else 2 # корректировка известного Эксель бага, что 1900 был висок-м г. - он не был\n",
    "        return pd.to_datetime('1900-01-01') + pd.to_timedelta(excel_time - adj,'D')\n",
    "\n",
    "#     def date_convert(self, date):\n",
    "#         ''' переводим в дату данные, т.к. часть данных в столбце представлена как число дней согл. Эксель'''\n",
    "#         if type(date) == int:\n",
    "#             return self.convert_excel_time(date)\n",
    "#         else:\n",
    "#             return date\n",
    "\n",
    "    def add_to_sql_data(self, engine):\n",
    "        sql_table_drop()\n",
    "        sql_table_create()\n",
    "        self.df_new.to_sql('sap_report_ar', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a526262",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# client_code_updater_v2() # обновление справочника кодов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1b85c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sql_table_drop() # Удаляет основную таблицу в БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_table_create() # СОЗДАЁТ ОСНОВНУЮ ТАБЛИЦУ В БД, ЕСЛИ ОНА ЕЩЁ НЕ СОЗДАНА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff11ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_base_to_csv() # экспортируем БД в .csv файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = \"2022-08-02\" # УДАЛИТЬ ДАННЫЕ ЗА ДАТУ В БД - в формате \"гггг-мм-дд\" указать нужную дату\n",
    "# delete_by_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce8a34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method = 'big' # 'raw', 'date' или 'big'\n",
    "handler = AR_Handler(method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f68618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# загрузка на SQL сервер\n",
    "\n",
    "\n",
    "# выдаёт ошибку, если каике-то строки \"важные\" пропали\n",
    "if (handler.df.shape[0] + handler.db_df.shape[0]) != (handler.df_new.shape[0]):\n",
    "    raise BaseException('We have lost {} number of rows'. \\\n",
    "                        format(handler.df_new.shape[0] - handler.df.shape[0] + handler.db_df.shape[0])\n",
    "                       )\n",
    "else:\n",
    "    engine = create_engine('postgresql+psycopg2://postgres:zXbkfdtr10-nmgk@localhost:5432/AR')\n",
    "    handler.add_to_sql_data(engine)\n",
    "    handler.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7eb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<<<<<<<<<< ---------------------;;;;;;;;;;;;;;;----------------..........................>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# всякиие черновики идут ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ab9ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj_cols = [col for col in handler.df_new.columns if handler.df_new[col].dtype == \"object\"]\n",
    "for col in obj_cols:\n",
    "    print(col + \":\", handler.df_new[col].map(str).map(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_columns_dict = {\n",
    "    'Контрагент': 'VARCHAR(100)',\n",
    "    'Документ': 'VARCHAR(100)',\n",
    "    'Дата': 'DATE',\n",
    "    'Сумма': 'NUMERIC',\n",
    "    'Валюта': 'VARCHAR(100)',\n",
    "    'Дата погашения': 'DATE',\n",
    "    'Дни просрочки САП': 'SMALLINT',\n",
    "    'Итого дебиторская задолженность': 'NUMERIC',\n",
    "    'Просроченная дебиторская задолженность САП': 'NUMERIC',\n",
    "    'Плановая дебиторская задолженность': 'NUMERIC',\n",
    "    'Дата формирования отчета': 'DATE',\n",
    "    'Код грузополучателя': 'BIGINT',\n",
    "    'Холдинг': 'VARCHAR(100)',\n",
    "    'Бизнес регион': 'VARCHAR(100)',\n",
    "    'Коммерсант': 'VARCHAR(100)',\n",
    "    'Канал': 'VARCHAR(100)',\n",
    "    'Директор': 'VARCHAR(100)',\n",
    "    'Дни просрочки': 'SMALLINT',\n",
    "    'Итого просроченная задолженность': 'NUMERIC'  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = str('\"\"\"CREATE TABLE sap_report_ar (id serial PRIMARY KEY, ')\n",
    "for key in final_columns:\n",
    "    query = query + \"(\" + key + ' ' + sql_columns_dict[key] + \"),\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b4d58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SELECT pg_terminate_backend(pg_stat_activity.pid)\n",
    "# FROM pg_stat_activity\n",
    "# WHERE pg_stat_activity.datname = 'AR'\n",
    "#   AND pid <> pg_backend_pid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn =  psycopg2.connect(host=\"localhost\", user=\"postgres\", password=\"zXbkfdtr10-nmgk\", database='AR')\n",
    "sql_query = \"SELECT * FROM sap_report_ar\"\n",
    "date_cols = [\"Дата\", \"Дата погашения\", \"Дата формирования отчета\"]\n",
    "import_df = pd.read_sql(sql_query, conn, parse_dates=date_cols).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00733408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee56415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(current_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
